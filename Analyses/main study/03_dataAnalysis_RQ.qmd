---
title: "Data analyses for S2 research questions"
author: "Julius Fenn, Louisa Estadieu"
format:
  html:
    toc: true
    toc-depth: 4
    html-math-method: katex
---



# Notes


# load cleaned data files

```{r}
#| label: load cleaned data files
#| warning: false

# sets the directory of location of this script as the current directory
# setwd(dirname(rstudioapi::getSourceEditorContext()$path))

### load packages
require(pacman)
p_load('tidyverse', 'jsonlite', 'magrittr', 'xlsx',
       'stargazer', 'psych', 'jtools', 'DT', 'ggstatsplot', 
       'lavaan', 
       'regsem', 'MplusAutomation', 'igraph', 'openxlsx',
       'reshape2',
       'gridExtra',
       'forcats')


setwd("outputs/01_dataPreperation/final")

### load questionnaire
questionnaire <- readRDS(file = "questionnaire_final.rds")
questionnaireCAMs <- readRDS(file = "questionnaireCAMs_final.rds")


### add type robot
questionnaire$choosen_Robot <- ifelse(test = questionnaire$choosen_Robot == "Rettungsroboter", yes = "rescue robot", no = "social assistance robot")

questionnaireCAMs$choosen_Robot <- ifelse(test = questionnaireCAMs$choosen_Robot == "Rettungsroboter", yes = "rescue robot", no = "social assistance robot")

networkIndicators_pre <- readRDS(file = "networkIndicators_pre_final.rds")
networkIndicators_post <- readRDS(file = "networkIndicators_post_final.rds")

# CAMfiles_combined <- readRDS(file = "CAMfiles_combined_final.rds")
CAMfiles_combined <- readRDS(file = "CAMfiles_combined_final_translated.rds")

CAMfiles_pre <- readRDS(file = "CAMfiles_pre_final.rds")
CAMfiles_post <- readRDS(file = "CAMfiles_post_final.rds")


### load functions
# print(getwd())
setwd("../../../../functions")
for(i in 1:length(dir())){
  # print(dir()[i])
  source(dir()[i], encoding = "utf-8")
}


setwd("../functions_CAMapp")
for(i in 1:length(dir())){
  # print(dir()[i])
  source(dir()[i], encoding = "utf-8")
}
rm(i)



### summary function
data_summary <- function(data, varname, groupnames){
  require(plyr)
  summary_func <- function(x, col){
    c(mean = mean(x[[col]], na.rm=TRUE),
      se = sd(x[[col]], na.rm=TRUE) / sqrt(length(x[[col]])))
  }
  data_sum<-ddply(data, groupnames, .fun=summary_func,
                  varname)
  data_sum <- plyr::rename(data_sum, c("mean" = varname))
  return(data_sum)
}
```

# descriptives

```{r}
table(questionnaireCAMs$typeChange)
round(x = table(questionnaireCAMs$typeChange) / nrow(questionnaireCAMs) * 100, digits = 2)
```

# data preperation


## only keep B, D

only keep B, D:

```{r}
tmp_ids <- questionnaireCAMs$PROLIFIC_PID[questionnaireCAMs$typeChange %in% c("B", "D")]

networkIndicators_pre <- networkIndicators_pre[str_remove_all(string = networkIndicators_pre$participantCAM, pattern = "_pre$") %in% tmp_ids, ]
networkIndicators_post <- networkIndicators_post[str_remove_all(string = networkIndicators_post$participantCAM, pattern = "_post$") %in% tmp_ids, ]

questionnaire <- questionnaire[questionnaire$PROLIFIC_PID %in% tmp_ids, ]
questionnaireCAMs <- questionnaireCAMs[questionnaireCAMs$PROLIFIC_PID %in% tmp_ids, ]

CAMfiles_combined[[1]] <- CAMfiles_combined[[1]][CAMfiles_combined[[1]]$participantCAM %in% tmp_ids, ]
CAMfiles_combined[[2]] <- CAMfiles_combined[[2]][CAMfiles_combined[[2]]$participantCAM %in% tmp_ids, ]
CAMfiles_combined[[3]] <- CAMfiles_combined[[3]][CAMfiles_combined[[3]]$participantCAM.y %in% tmp_ids, ] 
```

## add IDs to CAMfiles_combined

```{r}
CAMfiles_combined[[1]]$participantCAM[CAMfiles_combined[[1]]$CAM %in% CAMfiles_pre[[1]]$CAM] <- paste0(CAMfiles_combined[[1]]$participantCAM[CAMfiles_combined[[1]]$CAM %in% CAMfiles_pre[[1]]$CAM], "_pre")

CAMfiles_combined[[1]]$participantCAM[CAMfiles_combined[[1]]$CAM %in% CAMfiles_post[[1]]$CAM] <- paste0(CAMfiles_combined[[1]]$participantCAM[CAMfiles_combined[[1]]$CAM %in% CAMfiles_post[[1]]$CAM], "_post")
```

## set up long data

```{r}
# prepare data
### add pre post
networkIndicators_pre$timepoint <- "rigid"
networkIndicators_post$timepoint <- "soft"

### long data format
networkIndicators_long <- rbind(networkIndicators_pre, networkIndicators_post)

### ad ID
networkIndicators_long$ID <- c(1:(nrow(networkIndicators_long) / 2), 1:(nrow(networkIndicators_long) / 2))

### reformat variable
networkIndicators_long$timepoint <- factor(networkIndicators_long$timepoint, 
                                           levels = c("rigid", "soft"), 
                                           ordered = FALSE)

### add type robot
networkIndicators_long$typeRobot <- ifelse(test = !is.na(networkIndicators_long$valence_micro_Rettungsroboter), yes = "rescue robot", no = "social assistance robot")
table(networkIndicators_long$typeRobot)
table(questionnaireCAMs$choosen_Robot) * 2
```


# describe sample


```{r}
table(questionnaireCAMs$choosen_Robot)
# age for one person is missing
psych::describe(questionnaireCAMs[, c("socio_age")])
hist(questionnaireCAMs$socio_age)

# sex:
table(questionnaireCAMs$socio_sex)
round(x = table(questionnaireCAMs$socio_sex) / nrow(questionnaireCAMs) * 100, digits = 2) # 1 answer missing

table(questionnaireCAMs$socio_student)
table(questionnaireCAMs$socio_employment)

## split by robot
psych::describe(socio_age ~ choosen_Robot, data = questionnaireCAMs)
t.test(socio_age ~ choosen_Robot, data = questionnaireCAMs)

table(questionnaireCAMs$socio_sex, questionnaireCAMs$choosen_Robot)
chisq.test(questionnaireCAMs$socio_sex, questionnaireCAMs$choosen_Robot)
```
spent time on study

```{r}
psych::describe(x = questionnaireCAMs$total_min_prolific)
```


## describe CAMs

network parameters: 

```{r}
psych::describe(x = networkIndicators_long[, c("mean_valence_macro", "num_nodes_macro", "num_nodes_pos_macro", "num_nodes_neg_macro", "num_nodes_neut_macro", "num_nodes_ambi_macro")])

t.test(mean_valence_macro ~ typeRobot, data = networkIndicators_long)
t.test(num_nodes_macro ~ typeRobot, data = networkIndicators_long)
```


```{r}
psych::describe(x = questionnaireCAMs$feedCAM_repres)
```


spelling of terms:

```{r}
length(CAMfiles_combined[[1]]$text)
length(unique(CAMfiles_combined[[1]]$text))
sort(table(CAMfiles_combined[[1]]$text), decreasing = TRUE)[1:10]


sum(CAMfiles_combined[[1]]$comment != "")
tmp_comments <- sapply(strsplit(CAMfiles_combined[[1]]$comment, "\\s+"), function(x) length(x)) # by words
tmp_comments <- tmp_comments[tmp_comments != 0]
psych::describe(tmp_comments)
```





## feedback to the study


Question: Do you have any feedback or criticism of the online study? (in German)

```{r}
DT::datatable(questionnaireCAMs[,c("PROLIFIC_PID", "feedback_critic")], options = list(pageLength = 5)) 

## save feedbacks to summarize via LLM
setwd("outputs/03_dataAnalysis_RQ")
write.table(x = questionnaireCAMs$feedback_critic[!is.na(nchar(questionnaireCAMs$feedback_critic))], file = "feedback_critic.txt", row.names = FALSE)
```

## technical problems CAMEL

```{r}
DT::datatable(questionnaireCAMs[,c("PROLIFIC_PID", str_subset(string = colnames(questionnaireCAMs), pattern = "^feedCAM"))], options = list(pageLength = 5)) 

## technical problems
table(questionnaireCAMs$feedCAM_technicalprobs)
questionnaireCAMs$feedCAM_technicalprobsText[questionnaireCAMs$feedCAM_technicalprobs == 1]


hist(questionnaire$feedCAM_repres)
psych::describe(x = questionnaire$feedCAM_repres)
```




# R1: Perceived risks and benefits quantitative

## average emotional evaluation

```{r}
### post - pre difference of robot -> average valence
fit1_emo <- afex::aov_car(mean_valence_macro ~ timepoint*typeRobot + Error(ID / timepoint),
                      data = networkIndicators_long)
fit1a <- afex::aov_ez(id = "ID", dv = "mean_valence_macro",
                      data = networkIndicators_long, between=c("typeRobot"), within=c("timepoint"))
# partical eta squared
anova(fit1_emo, es = "pes")
# generalized eta squared
fit1a # > identical results

dfvalcor <- data_summary(networkIndicators_long, varname="mean_valence_macro",
                         groupnames=c("timepoint","typeRobot"))

dfvalcor$timepoint <- factor(dfvalcor$timepoint, levels = c("rigid", "soft"))

p_emo <- ggplot(dfvalcor, aes(x=timepoint, y=mean_valence_macro, fill=typeRobot)) +
  geom_bar(stat="identity", color="black",
           position=position_dodge()) +
  geom_errorbar(aes(ymin=mean_valence_macro-se, ymax=mean_valence_macro+se), width=.2,
                position=position_dodge(.9), linewidth = 1.3, color = "darkgray") + 
  scale_fill_manual(
    values = c("rescue robot" = "black", "social assistance robot" = "gray"),
    labels = c("rescue robot" = "rescue robot (RR)", "social assistance robot" = "social assistance robot (SAR)") # Custom legend labels
  ) +
  ggplot_theme + ylab(label = "average emotional evaluation") + 
  theme(axis.title.x = element_text(size=20), axis.title.y = element_text(size=20), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), legend.text = element_text(size=16), legend.title = element_text(size=18))  +
      labs(
        fill = "Robot Type" # Rename legend title
      )
print(p_emo)
```


## number of drawn concepts

### overall 


```{r}
### post - pre difference of robot -> number of concepts
fit1_concepts <- afex::aov_car(num_nodes_macro ~ timepoint*typeRobot + Error(ID / timepoint),
                      data = networkIndicators_long)
fit1a <- afex::aov_ez(id = "ID", dv = "num_nodes_macro",
                      data = networkIndicators_long, between=c("typeRobot"), within=c("timepoint"))
# partical eta squared
anova(fit1_concepts, es = "pes")
# generalized eta squared
fit1a # > identical results


dfvalcor <- data_summary(networkIndicators_long, varname="num_nodes_macro",
                         groupnames=c("timepoint","typeRobot"))

dfvalcor$timepoint <- factor(dfvalcor$timepoint, levels = c("rigid", "soft"))

p_concepts <- ggplot(dfvalcor, aes(x=timepoint, y=num_nodes_macro, fill=typeRobot)) +
  geom_bar(stat="identity", color="black",
           position=position_dodge()) +
  geom_errorbar(aes(ymin=num_nodes_macro-se, ymax=num_nodes_macro+se), width=.2,
              position=position_dodge(.9), linewidth = 1.3, color = "darkgray") + 
  ggplot_theme + ylab(label = "number of concepts") +
      scale_fill_manual(values = c("rescue robot" = "black", "social assistance robot" = "gray")) +
  theme(axis.title.x = element_text(size=20), axis.title.y = element_text(size=20), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), legend.text = element_text(size=16), legend.title = element_text(size=18))
print(p_concepts)
```


### positive 

```{r}
### post - pre difference of robot -> number of concepts
fit1_positive <- afex::aov_car(num_nodes_pos_macro ~ timepoint*typeRobot + Error(ID / timepoint),
                      data = networkIndicators_long)
fit1a <- afex::aov_ez(id = "ID", dv = "num_nodes_pos_macro",
                      data = networkIndicators_long, between=c("typeRobot"), within=c("timepoint"))

# partical eta squared
anova(fit1_positive, es = "pes")
# generalized eta squared
fit1a # > identical results


dfvalcor <- data_summary(networkIndicators_long, varname="num_nodes_pos_macro",
                         groupnames=c("timepoint","typeRobot"))

dfvalcor$timepoint <- factor(dfvalcor$timepoint, levels = c("rigid", "soft"))

p_positive <- ggplot(dfvalcor, aes(x=timepoint, y=num_nodes_pos_macro, fill=typeRobot)) +
  geom_bar(stat="identity", color="black",
           position=position_dodge()) +
  geom_errorbar(aes(ymin=num_nodes_pos_macro-se, ymax=num_nodes_pos_macro+se), width=.2,
                position=position_dodge(.9), linewidth = 1.3, color = "darkgray") + 
    scale_fill_manual(values = c("rescue robot" = "black", "social assistance robot" = "gray")) +
  ggplot_theme + ylab(label = "number of positive concepts") + 
  theme(axis.title.x = element_text(size=20), axis.title.y = element_text(size=20), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), legend.text = element_text(size=16), legend.title = element_text(size=18))
print(p_positive)
```


### negative 

```{r}
### post - pre difference of robot -> number of concepts
fit1_negative <- afex::aov_car(num_nodes_neg_macro ~ timepoint*typeRobot + Error(ID / timepoint),
                      data = networkIndicators_long)
fit1a <- afex::aov_ez(id = "ID", dv = "num_nodes_neg_macro",
                      data = networkIndicators_long, between=c("typeRobot"), within=c("timepoint"))
# partical eta squared
anova(fit1_negative, es = "pes")
# generalized eta squared
fit1a # > identical results


dfvalcor <- data_summary(networkIndicators_long, varname="num_nodes_neg_macro",
                         groupnames=c("timepoint","typeRobot"))

dfvalcor$timepoint <- factor(dfvalcor$timepoint, levels = c("rigid", "soft"))

p_negative <- ggplot(dfvalcor, aes(x=timepoint, y=num_nodes_neg_macro, fill=typeRobot)) +
  geom_bar(stat="identity", color="black",
           position=position_dodge()) +
  geom_errorbar(aes(ymin=num_nodes_neg_macro-se, ymax=num_nodes_neg_macro+se), width=.2,
            position=position_dodge(.9), linewidth = 1.3, color = "darkgray") + 
      scale_fill_manual(values = c("rescue robot" = "black", "social assistance robot" = "gray")) +
  ggplot_theme + ylab(label = "number of negative concepts") + 
  theme(axis.title.x = element_text(size=20), axis.title.y = element_text(size=20), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), legend.text = element_text(size=16), legend.title = element_text(size=18))
print(p_negative)
```

### ambivalent 


```{r}
### post - pre difference of robot -> number of concepts
fit1 <- afex::aov_car(num_nodes_ambi_macro ~ timepoint*typeRobot + Error(ID / timepoint),
                      data = networkIndicators_long)
fit1a <- afex::aov_ez(id = "ID", dv = "num_nodes_ambi_macro",
                      data = networkIndicators_long, between=c("typeRobot"), within=c("timepoint"))
# partical eta squared
anova(fit1, es = "pes")
# generalized eta squared
fit1a # > identical results


dfvalcor <- data_summary(networkIndicators_long, varname="num_nodes_ambi_macro",
                         groupnames=c("timepoint","typeRobot"))

dfvalcor$timepoint <- factor(dfvalcor$timepoint, levels = c("rigid", "soft"))

p <- ggplot(dfvalcor, aes(x=timepoint, y=num_nodes_ambi_macro, fill=typeRobot)) +
  geom_bar(stat="identity", color="black",
           position=position_dodge()) +
  geom_errorbar(aes(ymin=num_nodes_ambi_macro-se, ymax=num_nodes_ambi_macro+se), width=.2,
                position=position_dodge(.9)) +     
  scale_fill_manual(values = c("rescue robot" = "black", "social assistance robot" = "gray")) +
  ggplot_theme + ylab(label = "number of ambivalent concepts") + 
  theme(axis.title.x = element_text(size=20), axis.title.y = element_text(size=20), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), legend.text = element_text(size=16), legend.title = element_text(size=18))
print(p)
```

## group G1 graphics

```{r}
setwd("outputs/03_dataAnalysis_RQ")

# Adjust ggplot themes
common_theme <- theme(
  legend.position = "top",
  axis.title.x = element_text(size = 20),
  axis.title.y = element_text(size = 20),
  axis.text.x = element_text(size = 12),
  axis.text.y = element_text(size = 12),
  legend.text = element_text(size = 14),
  legend.title = element_text(size = 18),
  legend.key.size = unit(1.2, "cm")
)

# Apply the common theme to all plots
p_emo <- p_emo + common_theme + xlab(label = "intervention")
p_concepts <- p_concepts + common_theme + theme(legend.position = "none") + xlab(label = "intervention")
p_positive <- p_positive + common_theme + theme(legend.position = "none") + xlab(label = "intervention")




# Extract ANOVA results
extract_anova <- function(fit, label) {
  summary <- anova(fit, es = "pes")
  data.frame(
    DV = label,
    IV = rownames(summary),
    `Effect Size` = round(summary$pes, 2),
    `p` = paste0(format.pval(summary$`Pr(>F)`, digits = 2), ifelse(summary$`Pr(>F)` < 0.05, "*", ""))
  )
}

# Create ANOVA result tables
anova1 <- extract_anova(fit1_emo, "Avg. Emotional Evaluation")
anova2 <- extract_anova(fit1_concepts, "Number Concepts")
anova3 <- extract_anova(fit1_positive, "Number Positive Concepts")

# Combine all ANOVA results
anova_results <- bind_rows(anova1, anova2, anova3)

anova_results$IV[anova_results$IV == "typeRobot"] <- "SAR vs. RR"
anova_results$IV[anova_results$IV == "timepoint"] <- "intervention"
anova_results$IV[anova_results$IV == "typeRobot:timepoint"] <- "interaction"

# Load necessary packages
library(grid)
library(gridExtra)

# Create the table grob with increased width for the left column
table_grob <- tableGrob(
  anova_results,
  rows = NULL, # Removes row numbers
  theme = ttheme_default(
    core = list(
      fg_params = list(hjust = 0, x = 0.1, fontsize = 18) # Increase font size for table cells
    ),
    colhead = list(
      fg_params = list(fontface = "bold", fontsize = 20) # Increase font size for headers
    )
  )
)

# Adjust the column widths
table_grob$widths <- unit(c(.4, .2, .18, .15), "npc") # Increase width of the first column (adjust as needed)

# Add a caption to the table
table_with_caption <- arrangeGrob(
  textGrob(
    "Table 1: ANOVA Results for Emotional Evaluation, Number Concepts, and Positive Concepts",
    gp = gpar(fontsize = 16, fontface = "italic"), # Customize font size and style
    hjust = 0, x = 0.01 # Align to the left
  ),
  table_grob,
  ncol = 1, # Arrange vertically
  heights = c(0.2, 1) # Adjust height ratios for caption and table
)

# Combine plots and the table with caption into a grid
combined_plot <- grid.arrange(
  p_emo, p_concepts, p_positive, table_with_caption,
  ncol = 2, nrow = 2,
  heights = c(2, 2)
)
```



## additional analysis

```{r}
networkIndicators_long_within <- networkIndicators_long
networkIndicators_long_within$participantCAM <- str_remove(string = networkIndicators_long_within$participantCAM, pattern = "_pre$|_post$")


# positive concepts
## parametric t-test
ggwithinstats(
  data = networkIndicators_long_within,
  x = timepoint,
  y = num_nodes_pos_macro,
  type = "p",
  effsize.type = "d",
  conf.level = 0.95,
  title = "Parametric test"
)

# frequencies
## for positive concepts
tmp <- data.frame(post = networkIndicators_long_within$num_nodes_pos_macro[networkIndicators_long_within$timepoint == "rigid"], pre = networkIndicators_long_within$num_nodes_pos_macro[networkIndicators_long_within$timepoint == "soft"])
tmp$diff <- tmp$pre - tmp$post
tmp$diff_boolean <- tmp$diff == 0
psych::describe(tmp$diff)
sum(tmp$diff_boolean) / nrow(tmp)


# negative concepts
## parametric t-test
ggwithinstats(
  data = networkIndicators_long_within,
  x = timepoint,
  y = num_nodes_neg_macro,
  type = "p",
  effsize.type = "d",
  conf.level = 0.95,
  title = "Parametric test"
)

# frequencies
## for negative concepts
tmp <- data.frame(post = networkIndicators_long_within$num_nodes_neg_macro[networkIndicators_long_within$timepoint == "rigid"], pre = networkIndicators_long_within$num_nodes_neg_macro[networkIndicators_long_within$timepoint == "soft"])
tmp$diff <- tmp$pre - tmp$post
tmp$diff_boolean <- tmp$diff == 0
psych::describe(tmp$diff)
sum(tmp$diff_boolean) / nrow(tmp)
```


# R2: Perceived risks and benefits qualitative

## overall perspective


```{r}
ids_participants <- str_remove_all(string = CAMfiles_combined[[1]]$participantCAM, pattern = "_pre$|_post$")
ids_participants <- unique(ids_participants)

## number of participants
length(ids_participants)

## get dummy variable for pre / post
CAMfiles_combined[[1]]$timepoint <- str_extract_all(string = CAMfiles_combined[[1]]$participantCAM, pattern = "pre$|post$", simplify = TRUE)
# reformat variable
CAMfiles_combined[[1]]$timepoint <- factor(CAMfiles_combined[[1]]$timepoint, 
                                           levels = c("pre", "post"), 
                                           ordered = FALSE)
## get categories
CAMfiles_combined[[1]]$category <- str_remove_all(string = CAMfiles_combined[[1]]$text_summarized, pattern = "_positive$|_negative$|_ambivalent$|_neutral$")



## get condition
CAMfiles_combined[[1]]$condition <- NA
CAMfiles_combined[[1]]$condition[str_remove_all(string = CAMfiles_combined[[1]]$participantCAM, pattern = "_pre$|_post$") %in% questionnaireCAMs$PROLIFIC_PID[questionnaireCAMs$choosen_Robot == "social assistance robot"]] <- "social assistance robot"
CAMfiles_combined[[1]]$condition[str_remove_all(string = CAMfiles_combined[[1]]$participantCAM, pattern = "_pre$|_post$") %in% questionnaireCAMs$PROLIFIC_PID[questionnaireCAMs$choosen_Robot == "rescue robot"]] <- "rescue robot"





ids_categories <- CAMfiles_combined[[1]]$category
ids_categories <- unique(ids_categories)

ids_categories <- ids_categories[!ids_categories %in% c("RR", "SAR", "benefits", "risks")]


## number of categories
length(ids_categories)


table(CAMfiles_combined[[1]]$category)
table(CAMfiles_combined[[1]]$timepoint)
```

prepare data

```{r}
allConcepts_pre <- CAMfiles_combined[[1]][str_detect(string = CAMfiles_combined[[1]]$participantCAM, pattern = "_pre$"), ]
allConcepts_post <- CAMfiles_combined[[1]][str_detect(string = CAMfiles_combined[[1]]$participantCAM, pattern = "_post$"), ]
```

## CAMs, which added many concepts

```{r}
networkIndicators_post$diffConcepts <- networkIndicators_post$num_nodes_macro - networkIndicators_pre$num_nodes_macro

cbind(networkIndicators_post$diffConcepts[order(networkIndicators_post$diffConcepts, decreasing = TRUE)][1:12], networkIndicators_post$participantCAM[order(networkIndicators_post$diffConcepts, decreasing = TRUE)][1:12])


textPre <- CAMfiles_combined[[1]]$text[CAMfiles_combined[[1]]$participantCAM == "60fe7985ba99343ad0b893b7_pre"]
textPost <- CAMfiles_combined[[1]]$text[CAMfiles_combined[[1]]$participantCAM == "60fe7985ba99343ad0b893b7_post"]

textPost[!textPost %in% textPre]
textPre[!textPre %in% textPost]
```



## data preperation

### split by category

only a first look, table is *not sensitive if concept was deleted*

```{r}

table(CAMfiles_combined[[1]]$category, CAMfiles_combined[[1]]$timepoint)


mat <- table(CAMfiles_combined[[1]]$category, CAMfiles_combined[[1]]$condition)
mat[,1] <- round(x = mat[,1] / sum(questionnaireCAMs$choosen_Robot == "rescue robot"), digits = 2)
mat[,2] <- round(x = mat[,2] / sum(questionnaireCAMs$choosen_Robot == "social assistance robot"), digits = 2)
mat
```





### split by category and participant

#### create data frames of concepts constant (C), deleted (D), new (N)

```{r}
dat_pre_out <- data.frame()
dat_post_out <- data.frame()


for (i in 1:length(ids_participants)) {
  tmp_pre <-
    CAMfiles_combined[[1]][CAMfiles_combined[[1]]$participantCAM %in% paste0(ids_participants[i], "_pre"), ]
  tmp_post <-
    CAMfiles_combined[[1]][CAMfiles_combined[[1]]$participantCAM %in% paste0(ids_participants[i], "_post"), ]
  
  
  ## get date of concepts drawn by data collection tool (no interaction by user) - heuristic !!!:
  date_tmp <- tmp_post$date[tmp_post$date - min(tmp_post$date) <= .5] # less than half a second
  
  for (c in 1:length(ids_categories)) {
    if (any(
      c(
        tmp_pre$category %in% ids_categories[c],
        tmp_post$category %in% ids_categories[c]
      )
    )) {
      ## manually check if you could miss any words
      if (length(table(tmp_pre$text[tmp_pre$category %in% ids_categories[c]])[table(tmp_pre$text[tmp_pre$category %in% ids_categories[c]]) >= 2]) >= 1) {
        # cat("\npre data - multiple identical named concepts:\n", "in i:", i, ", c:", c, "\n")
      }
      if (length(table(tmp_post$text[tmp_post$category %in% ids_categories[c]])[table(tmp_post$text[tmp_post$category %in% ids_categories[c]]) >= 2]) >= 1) {
        # cat("\npost data - multiple identical named concepts:\n", "in i:", i, ", c:", c, "\n")
      }
      
      dat_pre <-
        tmp_pre[tmp_pre$category %in% ids_categories[c], c("participantCAM", "id" , "text", "value", "comment", "date", "x_pos", "y_pos", "category")]
      
      dat_post <-
        tmp_post[tmp_post$category %in% ids_categories[c], c("participantCAM", "id" , "text", "value", "comment", "date", "x_pos", "y_pos", "category")]
      
      
      ## set variables:
      if(nrow(dat_pre) >= 1){
        ## indicate type of concept:
        dat_pre$typeConcept <- NA
        
        checkOldDeleted <- FALSE
      }
      
      if(nrow(dat_post) >= 1){
        dat_post$originalConcept_date <- dat_post$date %in% date_tmp
        
        ## check if positions have changed - heuristic !!!:
        dat_post$originalConcept_position <- FALSE
        ## indicate if position was changed
        dat_post$changedPosition <- FALSE
        ## indicate if valence was changed
        dat_post$changedValence <- FALSE
        
        ## indicate type of concept:
        dat_post$typeConcept <- NA
        
        checkNewAdded <- FALSE
      }
      
      ## loop through if both data sets exists
      if(nrow(dat_pre) >= 1 && nrow(dat_post) >= 1){
        #> through dat_pre
        for(p in 1:nrow(dat_pre)){
          ## check positon:
          pos_tmp <- dat_pre[p,c("x_pos", "y_pos")]
          
          matching_id <- dat_post[dat_post$x_pos == pos_tmp$x_pos & dat_post$y_pos == pos_tmp$y_pos, "id"]
          
          dat_post$originalConcept_position[dat_post$id == matching_id] <- TRUE
          
          ## check valence
          value_tmp <- dat_post$value[dat_post$text %in% dat_pre$text[p]]
          
          if(length(value_tmp) != 0){
            if(dat_pre$value[p] != value_tmp[1]){
              dat_post$changedValence[dat_post$text %in% dat_pre$text[p]] <- TRUE
            }
          }
          
          ## indicate type of concept:
          if(dat_pre$text[p] %in% dat_post$text){
            dat_pre$typeConcept[p] <- "constant"
          }else{
            dat_pre$typeConcept[p] <- "deleted"
            # cat("\n deleted concepts:\n", "in i:", i, ", c:", c, "p:", p, "\n")
            checkOldDeleted <- TRUE
          }
        }
        
        #> through dat_post
        for(q in 1:nrow(dat_post)){
          ## indicate type of concept:
          if(dat_post$text[q] %in% dat_pre$text){
            dat_post$typeConcept[q] <- "constant"
          }else{
            dat_post$typeConcept[q] <- "new"
            # cat("\n new concepts:\n", "in i:", i, ", c:", c, "p:", p, "\n")
            checkNewAdded <- TRUE
          }
          
          ## indicate if concept changed positon
          if(dat_post$originalConcept_date[q] && !dat_post$originalConcept_position[q]){
            dat_post$changedPosition[q] <- TRUE
          }
        }
        
        
        if(all(checkOldDeleted, checkNewAdded)){
          # cat("\n deleted concepts, new concepts:\n", "in i:", i, ", c:", c, "p:", p, "\n")
        } 
      }
      
      
      ## indicate type of concept:
      if(nrow(dat_post) == 0){
        dat_pre$typeConcept <- "deleted"
      }
      
      if(nrow(dat_pre) == 0){
        dat_post$typeConcept <- "new"
      }
      
      if(any(is.na(dat_post$typeConcept))){
        cat("\n NA typeConcept:\n", "in i:", i, ", c:", c, "p:", p, "\n")
        stop()
      }
      
      dat_pre_out <- rbind(dat_pre_out, dat_pre)
      dat_post_out <- rbind(dat_post_out, dat_post)
  }
  }
}
```



```{r}
# check if I missed any typeConcept
sum(is.na(dat_pre_out$typeConcept))
sum(is.na(dat_post_out$typeConcept))

# check if any data set was multiple times added
sum(table(dat_pre_out$id) >= 2)
sum(table(dat_post_out$id) >= 2)

# number of entries
nrow(dat_pre_out)
nrow(dat_post_out)
# nrow(dat_post_out) - 535 + 68

# types
table(dat_pre_out$typeConcept)
table(dat_post_out$typeConcept)
```



```{r}
table(dat_post_out$changedPosition)
table(dat_post_out$changedValence)
```


```{r}
setwd("outputs/03_dataAnalysis_RQ")
xlsx::write.xlsx2(x = dat_pre_out, file = "concepts_conventional.xlsx")
xlsx::write.xlsx2(x = dat_post_out, file = "concepts_soft.xlsx")
```



#### create data.frame of all words for LLMs


```{r}
dat_pre_out$choosen_Robot <- NA
dat_post_out$choosen_Robot <- NA

## get IDs:
ids_SAR_pre <- questionnaireCAMs$participantCAMpre[questionnaireCAMs$choosen_Robot == "social assistance robot"]
ids_SAR_post <- questionnaireCAMs$participantCAMpost[questionnaireCAMs$choosen_Robot == "social assistance robot"]

ids_RR_pre <- questionnaireCAMs$participantCAMpre[questionnaireCAMs$choosen_Robot == "rescue robot"]
ids_RR_post <- questionnaireCAMs$participantCAMpost[questionnaireCAMs$choosen_Robot == "rescue robot"]


## fill in choosen_Robot variable:
dat_pre_out$choosen_Robot[dat_pre_out$participantCAM %in% c(ids_SAR_pre)] <- "social assistance robot"
dat_post_out$choosen_Robot[dat_post_out$participantCAM %in% c(ids_SAR_post)] <- "social assistance robot"

dat_pre_out$choosen_Robot[dat_pre_out$participantCAM %in% c(ids_RR_pre)] <- "rescue robot"
dat_post_out$choosen_Robot[dat_post_out$participantCAM %in% c(ids_RR_post)] <- "rescue robot"


sum(is.na(dat_pre_out$choosen_Robot))
sum(is.na(dat_post_out$choosen_Robot))


chooseRobot = "social assistance robot"
chooseRobot = "rescue robot"
```

```{r}
saveWordsByCategory <- function(chooseRobot, filterIDs = NA, changeName = NA) {

  wb <- openxlsx::createWorkbook()
  
  for (c in 1:length(ids_categories)) {
    ## pre data:
    tmp_pre <-
      dat_pre_out[dat_pre_out$category == ids_categories[c] &
                    dat_pre_out$choosen_Robot %in% chooseRobot,]
      if(all(!is.na(filterIDs))){
        tmp_pre <- tmp_pre[tmp_pre$participantCAM %in% filterIDs,]
      }
    
    ## post data:
    tmp_post <-
      dat_post_out[dat_post_out$category == ids_categories[c] &
                     dat_post_out$choosen_Robot %in% chooseRobot,]
      if(all(!is.na(filterIDs))){
        tmp_post <- tmp_post[tmp_post$participantCAM %in% filterIDs,]
      }
    
    
    ## set up data.frame
    tmp_numEntries <-  max(c(nrow(tmp_pre), nrow(tmp_post)))
    
    dat <- data.frame(
      constant = rep(x = NA, each = tmp_numEntries),
      constant_comments = rep(x = NA, each = tmp_numEntries),
      deleted = rep(x = NA, each = tmp_numEntries),
      deleted_comments = rep(x = NA, each = tmp_numEntries),
      new = rep(x = NA, each = tmp_numEntries),
      new_comments = rep(x = NA, each = tmp_numEntries)
    )
    
    ## constant:
    tmp <- tmp_pre$text[tmp_pre$typeConcept == "constant"]
    dat$constant <-
      c(tmp, rep(x = NA, each = (nrow(dat) - length(tmp))))
    tmp <- tmp_pre$comment[tmp_pre$typeConcept == "constant"]
    dat$constant_comments <-
      c(tmp, rep(x = NA, each = (nrow(dat) - length(tmp))))
    
    ## deleted:
    tmp <- tmp_pre$text[tmp_pre$typeConcept == "deleted"]
    dat$deleted <-
      c(tmp, rep(x = NA, each = (nrow(dat) - length(tmp))))
    tmp <- tmp_pre$comment[tmp_pre$typeConcept == "deleted"]
    dat$deleted_comments <-
      c(tmp, rep(x = NA, each = (nrow(dat) - length(tmp))))
    
    ## new:
    tmp <- tmp_post$text[tmp_post$typeConcept == "new"]
    dat$new <- c(tmp, rep(x = NA, each = (nrow(dat) - length(tmp))))
    tmp <- tmp_post$comment[tmp_post$typeConcept == "new"]
    dat$new_comments <-
      c(tmp, rep(x = NA, each = (nrow(dat) - length(tmp))))
    
    ## add worksheet
    addWorksheet(wb, ids_categories[c])
    writeData(wb, ids_categories[c], dat)
  }
  
  # Save the workbook
        if(!is.na(changeName)){
  saveWorkbook(wb, paste0(paste0(chooseRobot, changeName, collapse = "_"), "_multipleSheets_new.xlsx"), overwrite = TRUE)
        }else{
          saveWorkbook(wb, paste0(paste0(chooseRobot, collapse = "_"), "_multipleSheets_new.xlsx"), overwrite = TRUE)

      }
  
  
  return("Saved")
}
```


save overall:


```{r}
setwd("outputs/03_dataAnalysis_RQ")
saveWordsByCategory(chooseRobot = c("rescue robot", "social assistance robot"), filterIDs = NA, changeName = NA)
saveWordsByCategory(chooseRobot = c("rescue robot"), filterIDs = NA, changeName = NA)
saveWordsByCategory(chooseRobot = c("social assistance robot"), filterIDs = NA, changeName = NA)
```
save for gender:


for female:

```{r}
tmp_ids <- c(questionnaireCAMs$participantCAM_pre[questionnaireCAMs$socio_sex == "Female"],
questionnaireCAMs$participantCAMpost[questionnaireCAMs$socio_sex == "Female"])


setwd("outputs/03_dataAnalysis_RQ")
saveWordsByCategory(chooseRobot = c("rescue robot"), filterIDs = tmp_ids, changeName = "_female")
saveWordsByCategory(chooseRobot = c("social assistance robot"), filterIDs = tmp_ids, changeName = "_female")
```


for male:

```{r}
tmp_ids <- c(questionnaireCAMs$participantCAM_pre[questionnaireCAMs$socio_sex == "Male"],
questionnaireCAMs$participantCAMpost[questionnaireCAMs$socio_sex == "Male"])


setwd("outputs/03_dataAnalysis_RQ")
saveWordsByCategory(chooseRobot = c("rescue robot"), filterIDs = tmp_ids, changeName = "_male")
saveWordsByCategory(chooseRobot = c("social assistance robot"), filterIDs = tmp_ids, changeName = "_male")
```

## data analysis

### describe lists

overall:

```{r}
## constant (not deleted or added), deleted
table(dat_pre_out$typeConcept)
## constant, new
table(dat_post_out$typeConcept)
```

### get descriptive tables for each type of robot

separately for categories:

```{r}
### args:
# chooseRobot = "rescue robot"
# numParticipants =  sum(questionnaire$choosen_Robot == "rescue robot")

getDescriptiveTable <- function(chooseRobot, numParticipants) {
  dat <-
    data.frame(
      category = ids_categories,
      NCAMs = NA,
      PerCAMs = NA,
      Nconstant = NA,
      Ndeleted = NA,
      Nnew = NA,
      Mconstant = NA,
      Mdeleted = NA,
      Mnew = NA
    )
  
  for (c in 1:length(ids_categories)) {
    ## pre data:
    tmp_pre <-
      dat_pre_out[dat_pre_out$category == ids_categories[c] &
                    dat_pre_out$choosen_Robot %in% chooseRobot, ]
    ## post data:
    tmp_post <-
      dat_post_out[dat_post_out$category == ids_categories[c] &
                     dat_post_out$choosen_Robot %in% chooseRobot, ]
    
    
    #> ambivalent ratings (10) to 0
    tmp_pre$value <-
      ifelse(test = tmp_pre$value == 10,
             yes = 0,
             no = tmp_pre$value)
    tmp_post$value <-
      ifelse(test = tmp_post$value == 10,
             yes = 0,
             no = tmp_post$value)
    
    ## numbers:
    #> number of CAMs
    tmp_CAMs <- c(tmp_pre$participantCAM, tmp_post$participantCAM)
    dat$NCAMs[c] <-
      length(unique(tmp_CAMs)) # number CAMs involved in this category
    dat$PerCAMs[c] <-
      round(x = length(unique(tmp_CAMs)) / numParticipants * 100,
            digits = 2) # percentage (divided by total number of choosen robot)
    
    #> number of constant terms
    dat$Nconstant[c] <-
      round(
        x = sum(tmp_pre$typeConcept == "constant") / length(unique(tmp_CAMs)) * 1,
        digits = 2
      )
    
    #> number of deleted terms
    dat$Ndeleted[c] <-
      round(
        x = sum(tmp_pre$typeConcept == "deleted") / length(unique(tmp_CAMs)) * 1,
        digits = 2
      )
    
    #> number of constant terms
    dat$Nnew[c] <-
      round(
        x = sum(tmp_post$typeConcept == "new") / length(unique(tmp_CAMs)) * 1,
        digits = 2
      )
    
    ## means:
    #> mean of constant terms
    dat$Mconstant[c] <-
      mean(tmp_pre$value[tmp_pre$typeConcept == "constant"])
    
    #> mean of constant terms
    dat$Mdeleted[c] <-
      mean(tmp_pre$value[tmp_pre$typeConcept == "deleted"])
    
    #> mean of constant terms
    dat$Mnew[c] <-
      mean(tmp_post$value[tmp_post$typeConcept == "new"])
  }
  colnames(dat) <-
    c(
      "category",
      "numCAMs",
      "perCAMs",
      "avgConstant",
      "avgOld",
      "avgNew",
      "Mconstant",
      "Mold",
      "Mnew"
    )
  
  
  dat$Mconstant <- round(x = dat$Mconstant, digits = 2)
  dat$Mold <- round(x = dat$Mold, digits = 2)
  dat$Mnew <- round(x = dat$Mnew, digits = 2)

  return(dat)
}
```


```{r}
#| warning: false

## for rescue robot
num <- sum(questionnaire$choosen_Robot == "rescue robot")
tmp_RR <- getDescriptiveTable(chooseRobot = "rescue robot", numParticipants = num)
DT::datatable(data = tmp_RR)
```

```{r}
## for social assistance robot
num <- sum(questionnaire$choosen_Robot == "social assistance robot")
tmp_SAR <- getDescriptiveTable(chooseRobot = "social assistance robot", numParticipants = num)
DT::datatable(data = tmp_SAR)

```




save as HTML: 

```{r}
setwd("outputs/03_dataAnalysis_RQ")
stargazer(tmp_RR, type = "html", out = "rescue robot_table.html", summary = FALSE)
stargazer(tmp_SAR, type = "html", out = "social assistance robot_table.html", summary = FALSE)
```



### Graphic 1 (quantitative)

```{r}
# Data for r1
data_r1 <- tmp_RR[!tmp_RR$category %in% c("RCPP", "RCPN", "RCN", "RCA"), c("category", "avgConstant", "avgNew")]
data_r1$group = "RR"
colnames(data_r1)[c(2,3)] <- c("constant", "new")

# Data for r2
data_r2 <- tmp_SAR[!tmp_SAR$category %in% c("RCPP", "RCPN", "RCN", "RCA"), c("category", "avgConstant", "avgNew")]
data_r2$group = "SAR"
colnames(data_r2)[c(2,3)] <- c("constant", "new")

# Combine the data
data_combined <- rbind(data_r1, data_r2)

data_combined <- data_combined[data_combined$category %in% unique(c(data_r1$category[order(data_r1$new, decreasing = TRUE)][1:5], data_r2$category[order(data_r2$new, decreasing = TRUE)][1:5])),]


# Reshape the data to long format for ggplot
data_long <- melt(data_combined, id.vars = c("category", "group"), 
                  variable.name = "type", value.name = "value")

# Create a new column to distinguish between the groups and types for coloring
data_long$group_type <- interaction(data_long$group, data_long$type)

# rename group_type
levels(data_long$group_type) <- c("RR (constant)", "SAR (constant)", "RR (new)", "SAR (new)")

# Create the grouped barplot
ggplot(data_long, aes(x = category, y = value, fill = group_type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), width = 0.9) +
    geom_text(aes(label = value, y = value + 0.02), 
            position = position_dodge(width = 0.7), vjust = 0, hjust = .2) +
  coord_flip() +
  labs(title = "Grouped Barplot of constant and new terms of robots for single categories",
       x = "Category",
       y = "Average number of drawn concepts per participant",
       fill = "Robot (type)") +
  theme_minimal() +
  scale_fill_manual(values = c("RR (constant)" = "darkblue", "SAR (constant)" = "lightblue", 
                               "RR (new)" = "darkgreen", "SAR (new)" = "lightgreen")) +
  theme(legend.position = "top",
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12))
```


```{r}
setwd("outputs/03_dataAnalysis_RQ")

# Data for r1
data_r1 <- tmp_RR[!tmp_RR$category %in% c("RCPP", "RCPN", "RCN", "RCA"), c("category", "avgConstant", "avgNew")]
data_r1$group = "RR"
colnames(data_r1)[c(2,3)] <- c("rigid", "soft")

# Data for r2
data_r2 <- tmp_SAR[!tmp_SAR$category %in% c("RCPP", "RCPN", "RCN", "RCA"), c("category", "avgConstant", "avgNew")]
data_r2$group = "SAR"
colnames(data_r2)[c(2,3)] <- c("rigid", "soft")

# Combine the data
data_combined <- rbind(data_r1, data_r2)

# Sort categories by "soft" (avgNew) values
data_combined <- data_combined[order(data_combined$soft, decreasing = TRUE), ]

# Select the top categories
data_combined <- data_combined[data_combined$category %in% unique(c(data_r1$category[order(data_r1$soft, decreasing = TRUE)][1:5], 
                                                                    data_r2$category[order(data_r2$soft, decreasing = TRUE)][1:5])),]

# Reshape the data to long format for ggplot
data_long <- melt(data_combined, id.vars = c("category", "group"), 
                  variable.name = "type", value.name = "value")

# Ensure "rigid" is always below "soft" in the stack
data_long$type <- factor(data_long$type, levels = c("soft", "rigid"))

# Add line breaks in category labels for better fit
data_long$category <- recode(data_long$category,
                             "AP" = "Anthropomorphism\npos.",
                             "HRIN" = "Human-Robot-\nInteraction neg.",
                             "HRIP" = "Human-Robot-\nInteraction pos.",
                             "R" = "Risk",
                             "SA" = "Safety",
                             "TL" = "Technological\nlimitation",
                             "TP" = "Technological\npossibilities"
)

# Reorder categories by the sum of values
data_long$category <- fct_reorder(data_long$category, data_long$value, .fun = sum, .desc = TRUE)

# Create the stacked barplot
p <- ggplot(data_long, aes(x = group, y = value, fill = type)) +
  geom_bar(stat = "identity", position = "stack", width = 0.5) +  # Reduce bar width
  geom_text(aes(label = sprintf("%.2f", value)),  # Add value labels with 2 decimal places
            position = position_stack(vjust = 0.5),  # Position labels in the middle of the stack
            size = 3.5, color = "white") +  # Adjust text size and color
  facet_wrap(~category, scales = "free_x", nrow = 1) +  # Reduce facet spacing
  labs(x = "Robot Type (RR or SAR)",
       y = "Average Number of Concepts Drawn per CAM",
       fill = "Concept Type") +
  theme_minimal() +
  scale_fill_manual(values = c("rigid" = "black", "soft" = "gray")) +
  theme(legend.position = "top",
        legend.text = element_text(size = 12),
        legend.title = element_text(size = 14),
        legend.key.size = unit(0.8, "cm"),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        strip.text = element_text(size = 12, face = "bold"),  # Adjust font size for category names
        strip.placement = "outside",  # Place labels outside to reduce clutter
        panel.spacing = unit(0.8, "lines"))  # Increase spacing between facets

print(p)



# Save the plot
ggsave(filename = "R2_G1.pdf", plot = p, width = 14, height = 8)
ggsave(filename = "R2_G1.jpeg", plot = p, width = 14, height = 8)
```






# R3: Perceived risks and benefits mediated by gender and age

qualitative analyses using LLMs


# ADDITIONAL ANALYSES

## check single scales and compute mean variables

### Almere

#### Anxiety dimension


```{r}
#| label: Almere Anxiety
#| warning: false

regEx <- "^Almere.*anx$"
nameScale <- "Almere - Anxiety"
nameVariable <- "mean_AlmereAnxiety"

### number of items
sum(str_detect(string = colnames(questionnaireCAMs), pattern = regEx))

### get correlation plot, descriptives, EFA, CFA

### EFA
tmp <- CFAstats(dataset = questionnaireCAMs, regularExp = regEx, labelLatent = str_remove(string = nameVariable, pattern = "mean_"), 
                showPlots = TRUE, 
                computeEFA = TRUE, 
                computeCFA = TRUE, 
                computeCFAMplus = FALSE)

### variable mean
questionnaireCAMs[[nameVariable]]  <- questionnaireCAMs %>%
  select(matches(regEx)) %>%
  rowMeans(na.rm = TRUE)
```


#### Attitude dimension


```{r}
#| label: Almere Attitude
#| warning: false

regEx <- "^Almere.*att$"
nameScale <- "Almere - Attitude"
nameVariable <- "mean_AlmereAttitude"

### number of items
sum(str_detect(string = colnames(questionnaireCAMs), pattern = regEx))

### get correlation plot, descriptives, EFA, CFA

### EFA
tmp <- CFAstats(dataset = questionnaireCAMs, regularExp = regEx, labelLatent = str_remove(string = nameVariable, pattern = "mean_"), 
                showPlots = TRUE, 
                computeEFA = TRUE, 
                computeCFA = TRUE, 
                computeCFAMplus = FALSE)

### variable mean
questionnaireCAMs[[nameVariable]]  <- questionnaireCAMs %>%
  select(matches(regEx)) %>%
  rowMeans(na.rm = TRUE)
```


### Li & Wang (2021)

#### Anthropomorphism dimension


```{r}
#| label: Li & Wang Anthropomorphism
#| warning: false

regEx <- "^LiWang.*anthropomorphism$"
nameScale <- "LiWang - Anthropomorphism"
nameVariable <- "mean_LiWangAnthropomorphism"

### number of items
sum(str_detect(string = colnames(questionnaireCAMs), pattern = regEx))

### get correlation plot, descriptives, EFA, CFA

### EFA
tmp <- CFAstats(dataset = questionnaireCAMs, regularExp = regEx, labelLatent = str_remove(string = nameVariable, pattern = "mean_"), 
                showPlots = TRUE, 
                computeEFA = TRUE, 
                computeCFA = TRUE, 
                computeCFAMplus = FALSE)

### variable mean
questionnaireCAMs[[nameVariable]]  <- questionnaireCAMs %>%
  select(matches(regEx)) %>%
  rowMeans(na.rm = TRUE)
```


#### Autonomy dimension


```{r}
#| label: Li & Wang Autonomy
#| warning: false

regEx <- "^LiWang.*autonomy$"
nameScale <- "LiWang - Autonomy"
nameVariable <- "mean_LiWangAutonomy"

### number of items
sum(str_detect(string = colnames(questionnaireCAMs), pattern = regEx))

### get correlation plot, descriptives, EFA, CFA

### EFA
tmp <- CFAstats(dataset = questionnaireCAMs, regularExp = regEx, labelLatent = str_remove(string = nameVariable, pattern = "mean_"), 
                showPlots = TRUE, 
                computeEFA = TRUE, 
                computeCFA = TRUE, 
                computeCFAMplus = FALSE)

### variable mean
questionnaireCAMs[[nameVariable]]  <- questionnaireCAMs %>%
  select(matches(regEx)) %>%
  rowMeans(na.rm = TRUE)
```



### General Attitudes Towards Robots Scale, GAToRS (2022)

#### Personal Level Positive Attitude

```{r}
#| label: GAToRS PP
#| warning: false

regEx <- "^GAToRS.*pp$"
nameScale <- "GAToRS - PP"
nameVariable <- "mean_GAToRSpp"

### number of items
sum(str_detect(string = colnames(questionnaireCAMs), pattern = regEx))

### get correlation plot, descriptives, EFA, CFA

### EFA
tmp <- CFAstats(dataset = questionnaireCAMs, regularExp = regEx, labelLatent = str_remove(string = nameVariable, pattern = "mean_"), 
                showPlots = TRUE, 
                computeEFA = TRUE, 
                computeCFA = TRUE, 
                computeCFAMplus = FALSE)

### variable mean
questionnaireCAMs[[nameVariable]]  <- questionnaireCAMs %>%
  select(matches(regEx)) %>%
  rowMeans(na.rm = TRUE)
```




#### Personal Level Negative Attitude

```{r}
#| label: GAToRS PN
#| warning: false

regEx <- "^GAToRS.*pn$"
nameScale <- "GAToRS - pn"
nameVariable <- "mean_GAToRSpn"

### number of items
sum(str_detect(string = colnames(questionnaireCAMs), pattern = regEx))

### get correlation plot, descriptives, EFA, CFA

### EFA
tmp <- CFAstats(dataset = questionnaireCAMs, regularExp = regEx, labelLatent = str_remove(string = nameVariable, pattern = "mean_"), 
                showPlots = TRUE, 
                computeEFA = TRUE, 
                computeCFA = TRUE, 
                computeCFAMplus = FALSE)

### variable mean
questionnaireCAMs[[nameVariable]]  <- questionnaireCAMs %>%
  select(matches(regEx)) %>%
  rowMeans(na.rm = TRUE)
```


#### Societal Level Positive Attitude

```{r}
#| label: GAToRS SP
#| warning: false

regEx <- "^GAToRS.*sp$"
nameScale <- "GAToRS - sp"
nameVariable <- "mean_GAToRSsp"

### number of items
sum(str_detect(string = colnames(questionnaireCAMs), pattern = regEx))

### get correlation plot, descriptives, EFA, CFA

### EFA
tmp <- CFAstats(dataset = questionnaireCAMs, regularExp = regEx, labelLatent = str_remove(string = nameVariable, pattern = "mean_"), 
                showPlots = TRUE, 
                computeEFA = TRUE, 
                computeCFA = TRUE, 
                computeCFAMplus = FALSE)

### variable mean
questionnaireCAMs[[nameVariable]]  <- questionnaireCAMs %>%
  select(matches(regEx)) %>%
  rowMeans(na.rm = TRUE)
```


#### Societal Level Negative Attitude

```{r}
#| label: GAToRS SN
#| warning: false

regEx <- "^GAToRS.*sn$"
nameScale <- "GAToRS - sn"
nameVariable <- "mean_GAToRSsn"

### number of items
sum(str_detect(string = colnames(questionnaireCAMs), pattern = regEx))

### get correlation plot, descriptives, EFA, CFA

### EFA
tmp <- CFAstats(dataset = questionnaireCAMs, regularExp = regEx, labelLatent = str_remove(string = nameVariable, pattern = "mean_"), 
                showPlots = TRUE, 
                computeEFA = TRUE, 
                computeCFA = TRUE, 
                computeCFAMplus = FALSE)

### variable mean
questionnaireCAMs[[nameVariable]]  <- questionnaireCAMs %>%
  select(matches(regEx)) %>%
  rowMeans(na.rm = TRUE)
```

## differences survey means

```{r}
## split by robot
psych::describe(mean_AlmereAnxiety + mean_AlmereAttitude + mean_LiWangAnthropomorphism + mean_LiWangAutonomy + mean_GAToRSpp + mean_GAToRSpn + mean_GAToRSsp + mean_GAToRSsn ~ choosen_Robot, data = questionnaireCAMs)
```
