
[
    {
        "robot": "SAR",
        "category": "HRIN",
        "coded_texts": [
            "no real relationships",
            "relationships: can disrupt human relationships",
            "dependency: Similar to YouTubers or streamers, a kind of pseudo-relationship that possibly makes you dependent",
            "unsuitable for mentally disabled: Overwhelm, possibly fear",
            "no real bond",
            "**Dependence on robots:** People no longer seek human contact but instead rely solely on robots (similar to online forums today and social gatherings in person in the past)<sup>reduced human contact; social isolation</sup>",
            "emotional bond: People can form too strong an emotional attachment to robots",
            "dependency: The person will be dependent.",
            "possible dependence",
            "**no physical contact:**<sup>perceived negative HRI</sup> Physical contact such as **placing a hand on the shoulder, hugs**<sup>loss of gestures</sup> etc. are lost in the process.",
            "***\n\nlack of empathy: **Will the Robbi be able to adequately address emotions, or react to them and control his actions accordingly?**<sup>emotional understanding</sup>",
            "***possible emotional dependencies***<sup>emotional understanding</sup>",
            "***feelings of fear: Especially older people / dementia patients could be afraid of machines***<sup>fear; older adults; dementia patients</sup>",
            "no friendship",
            "No human reference",
            "fear of technology",
            "unlearning human interaction",
            "changed human interaction",
            "reaction instead of interaction",
            "individuality of people: Learned reactions from robots can elicit different responses depending on the person. For one, **physical closeness is pleasant, for another it is not or even triggering**<sup>individual response</sup>.",
            "***reduction of social contacts: If humans are replaced by robots, some people may still feel lonely because they don't regard robots as a suitable replacement.***<sup>loneliness risk</sup>",
            "digital competence: **Staff AND clientele must be competent in handling robots**<sup>competence</sup> - particularly questionable with older people",
            "***rejection of technology: Especially older people reject newer technologies.***<sup>age-related attitudes</sup>",
            "overdependence: Since it is better and cheaper",
            "Dependence on robots",
            "impersonal: **Robots are not humans**<sup>impersonal</sup>",
            "greater risk of dependency",
            "lack of contact",
            "Feel uncomfortable: Some people might **feel uncomfortable**<sup>perceived negative HRI</sup> if robots instead of humans take care of them",
            "***fear of robots***<sup>fear</sup>: some people feel scared of robots and would not let them help",
            "People become **dependent**<sup>dependence</sup>: Dependence on assistance robots",
            "dependency: The person could become **dependent on the robot and cannot live without him**<sup>dependence</sup>.",
            "No human contact: **Robots cannot replace humans**<sup>impersonal</sup>",
            "**humans emotionally replaced: human closeness is being replaced with assistance robots**<sup>emotional replacement</sup>",
            "lack of human warmth: **the feeling of interacting with a real person is important**<sup>emotional connection</sup>",
            "***emotional blunting: If robots replace the last human contact for elderly people, this could lead to emotional numbness.***<sup>emotional replacement</sup>",
            "dependency: Danger of dependency on the assistance robot, less contact with people",
            "possible dependency: Dependency could arise due to 24/7 availability - but this could be reduced by scheduled break times.",
            "emotional dependence: **People could treat a soft robot emotionally like a real animal**<sup>emotional dependence</sup>.",
            "have **emotional dependence**<sup>emotional dependence</sup>",
            "know-how required: **about operating the robot**<sup>technical knowledge</sup>",
            "social dependency",
            "normal interaction: Maybe it's no longer possible to correctly respond to/embody emotional human interaction.",
            "possible dependence: Users could become dependent",
            "recognition of emotions",
            "too impersonal: Contact with real people is important.",
            "no \"real\" contact",
            "no social interaction: Interaction with people cannot be replaced by robots",
            "**unhealthy relationships**<sup>unhealthy relationships</sup>: People could develop unhealthy relationships with robots and thereby lose more contact with humans.",
            "***fake interaction: it is a mean trick to pretend to people a human interaction, who may not be able to perceive everything correctly themselves***<sup>deception</sup>",
            "create dependency",
            "no proper interaction",
            "***communication difficulties: Old people can have communication difficulties that the robot does not understand.***<sup>age-related attitudes; competence</sup>",
            "***emotional skills: Can robots really map the emotional spectrum of a human?***<sup>lack of insight</sup>",
            "unacceptance among nursing home residents: Nursing home residents do not interact",
            "no human contact: Older people or people with special needs receive less genuine positive human contact.",
            "undesired emotional relationships",
            "human needs difficult: Meeting human needs through robots can prove to be difficult or even a mistake.",
            "creating dependencies",
            "alternative to real: If real people potentially cause too much overwhelm for autistic individuals.",
            "**animal-like shape**<sup>The animal-like shape leads to fewer associations with human counterpart</sup>: The animal-like shape leads to fewer associations with human counterpart",
            "loss of social skills",
            "(emotional) influence possible",
            "emotional dependence",
            "communication barrier",
            "change in social behavior: from patients who primarily interact with robots",
            "addiction: People will not try to change their social environment if they become dependent on robots.",
            "**lack of humanity: missing human interactions and empathy cannot be replaced**<sup>lack of humanity</sup>",
            "risk of dependency",
            "**strong emotional dependence**: Negative reaction when the robot breaks down - similar to the death of a pet<sup>emotional dependence</sup>",
            "influence of behavior",
            "disconnectedness: The interaction between robot and human would be incompatible",
            "fake relationships",
            "***fear due to strangeness: Above all, elderly people could be confused by the concept of robots.***<sup>fear</sup>"
          ],
  "code_descriptions": {
    "loss of gestures": "Captures instances where participants express a sense of diminished emotional connection or understanding due to the absence or reduction of physical gestures in interactions with socially assistive robots, such as hugs or placing a hand on the shoulder.",
    "emotional understanding": "Captures instances where participants express concerns or expectations regarding a socially assistive robot's ability to understand and respond to human emotions in a meaningful way, including reacting to emotions appropriately and controlling actions based on emotional cues.",
    "fear": "Captures instances where participants express concerns or apprehension, particularly among older individuals or dementia patients, regarding the use of socially assistive robots in Human-Robot-Interaction, highlighting potential fears associated with machine interaction.",
    "individual response": "Highlights the varying individual reactions to physical closeness in Human-Robot-Interaction, ranging from comfort to discomfort or triggers, emphasizing diverse personal preferences.",
    "loneliness risk": "Identifies concerns related to the potential risk of loneliness stemming from the reduction of social contacts when humans are replaced by robots in socially assistive roles.",
    "competence": "Denotes references to the necessity for both staff and clients to possess the necessary skills and knowledge to effectively interact with socially assistive robots in the context of perceived risks and benefits.",
    "age-related attitudes": "Captures instances where older individuals express skepticism or resistance towards adopting new technologies, particularly in the context of socially assistive robots and Human-Robot-Interaction.",
    "impersonal": "Identifies instances where participants express a preference for human-like qualities in interactions with robots, highlighting a desire for more personalized and emotionally engaging experiences.",
    "dependence": "Identifies instances where participants discuss reliance on socially assistive robots for various tasks, emphasizing the nuanced perspectives on the benefits and risks of dependence, including reduced human contact and emotional impacts.",
    "emotional dependence": "Captures instances where individuals form emotional attachments to socially assistive robots, viewing them as companions or substitutes for human relationships. This includes concerns about emotional blunting, pseudo-relationships, and potential overdependence.",
    "technical knowledge": "Identifies instances where participants discuss the importance of possessing technical knowledge for effectively operating socially assistive robots, including managing potential communication barriers and ensuring smooth interactions.",
    "unhealthy relationships": "Identifies instances where participants express concerns about forming unhealthy dynamics with socially assistive robots, potentially leading to decreased human contact and distorted emotional interactions.",
    "deception": "Identifies instances where participants express concerns about the unethical practice of simulating human interaction with socially assistive robots, potentially leading to misunderstandings or misperceptions.",
    "superficial interaction": "Captures concerns that interactions with robots may feel insincere or lack depth compared to human connections, raising questions about the authenticity of such engagements.",
    "lack of humanity": "Captures instances where participants emphasize the irreplaceable value of human empathy and connection, which cannot be adequately replicated by interactions with robots."
  }
}
]