[
    {
        "robot": "SAR",
        "category": "AN",
        "coded_texts": [
            "feigning empathy: **The described robots do not react as a living being would**<sup>empathy</sup>. They have no will and no feelings. **The reactions are deceptive as they suggest empathy to those in need**<sup>deception</sup>.",
            "limited emotional intelligence",
            "No human empathy",
            "***\n\n**without empathy**<sup>empathy</sup>: Cannot respond to emotions despite objectivity or possibly not like a human would.",
            "life-like properties",
            "not creative: no imagination",
            "no real person",
            "Lack of emotions",
            "Lack of empathy",
            "**Not empathetic (enough): Robots cannot empathize or understand human emotions.**<sup>empathy</sup>",
            "lack of empathy",
            "no emotions",
            "No human warmth",
            "Replacement impossible: **real human interaction is complex and nuanced, a mechanical replacement is hardly possible**<sup>complexity; limitations</sup>",
            "not human-like",
            "emotional integrity: **The robot cannot offer human emotions to people**<sup>limitations</sup>",
            "expectation of AI",
            "not spontaneous: **Assistance robots cannot react spontaneously to new experiences**<sup>lack of adaptability</sup>.",
            "***no empathy: The robots cannot feel or express empathy, only artificial empathy, which is often seen through***<sup>deception</sup>",
            "only fake empathy",
            "lack of empathy?",
            "societal awkwardness",
            "no empathy",
            "uncanny valley",
            "reading emotions: can misinterpret emotions",
            "***Lack of intuition: all skills are programmed and therefore based on a database. Human intuition etc. are not possible***<sup>intuition</sup>",
            "no human closeness",
            "***humanization of robots: Robots can become reference persons through use with children or elderly people, which could potentially be harmful to the person***<sup>harmful potential</sup>. **Hacking and then coaxing the person to do something**<sup>manipulation</sup>. **Emotional bonds are broken when the robot is broken**<sup>emotional impact</sup>.",
            "seriousness: Is Robi taken seriously as an assistant?",
            "\"uncanny valley\": **Anthropomorphized robots are often perceived as creepy**<sup>perception</sup>",
            "human warmth: **and gentle touch (comfort) cannot really be conveyed by the robot**<sup>limitations</sup>",
            "negative perceptions: opposite robots",
            "therapy robots: **People should help people and not be replaced by robots**<sup>ethics</sup>",
            "disappearing boundaries: **The line between human and machine is disappearing**<sup>technological advancement</sup>",
            "uncanny valley: **Robots could suddenly seem alien and scary in interaction, when one becomes aware of their artificiality again**<sup>uncanny valley</sup>",
            "no spontaneous action",
            "emotionally cold",
            "no \"real\" empathy",
            "limitation: **Robots can only partially replace human communication**<sup>limitations</sup>"
        ],

  "code_descriptions": {
    "deception": "Identifies instances in the data where participants describe deceptive behaviors or actions that imply empathy towards individuals requiring assistance.",
    "interaction": "Captures references to the intricate and multifaceted nature of human interaction, suggesting skepticism towards the feasibility of mechanical or life-like substitutes.",
    "limitations": "Highlights the acknowledgment of the limitations of robots in understanding and responding to human emotions and needs, particularly in providing genuine emotional support and connection.",
    "intuition": "Captures instances where participants express skepticism towards socially assistive robots' ability to exhibit human-like intuition, emphasizing reliance on programmed skills over intuitive understanding.",
    "harmful potential": "Identifies instances where the anthropomorphism of socially assistive robots is perceived as having the potential to cause harm, particularly in scenarios involving vulnerable populations like children or the elderly.",
    "manipulation": "Identifies instances in the data where individuals describe actions involving unauthorized access or coercion to influence behavior, raising concerns about manipulation rather than assistance.",
    "emotional impact": "Captures instances where participants express the disruption or strain on emotional connections when the socially assistive robot malfunctions or ceases to function.",
    "ethical concerns": "Captures concerns about the potential psychological harm caused by over-anthropomorphizing robots, particularly when emotional bonds are formed that could break due to malfunctions or manipulative use.",
    "technological advancement": "Identifies instances where participants express observations or concerns about the blurring boundary between humans and machines in the context of socially assistive robots, reflecting on the impact of technological advancement.",
    "uncanny valley": "Identifies instances where participants express discomfort or fear when socially assistive robots exhibit characteristics that remind them of their artificial nature, leading to a sense of unease or alienation.",
    "lack of empathy": "Captures the inability of socially assistive robots to convey human warmth or genuine emotional connection, highlighting a key concern in the context of perceived negative anthropomorphism."
          }
    }
]