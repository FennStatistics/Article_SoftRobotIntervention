[
    {
        "robot": "RR",
        "category": "AN",
        "coded_texts": [
            "limited autonomy",
            "No feelings: **Can't empathize with the victims' feelings when the robots work autonomically**<sup>empathy</sup>",
            "decision-making ability",
            "lack of humanity: **AI and no human**<sup>perspective</sup>. what does it look like from the perspective of people who are being saved",
            "lack of empathy",
            "no emotion",
            "**intimidating appearance**<sup>perceived negative anthropomorphism</sup>: a robot could seem frightening",
            "autonomy: **Autonomy as a contradiction to rescue goals**<sup>lack of alignment</sup>",
            "lack of empathy: Victims could be treated improperly",
            "no human thinking",
            "no empathy",
            "limited cognition",
            "have no feelings",
            "lack of emotional support: Sometimes people need to endure in their predicament, should they be trapped. Here, a human rescuer can provide emotional support.",
            "***imitation of nature: Human-like characteristics might not be well received by every person and could cause discomfort.***<sup>perceived negative anthropomorphism</sup>",
            "lack of responsibility: **with autonomous robots**<sup>lack of alignment</sup>",
            "lack of human judgment",
            "***errors in autonomy***<sup>perceived negative anthropomorphism</sup>: Autonomously working robots can make mistakes because they judge complex relationships worse.",
            "**inhuman: A victim that can be saved is probably not used to dealing with such machines and would not know how to behave. It cannot show empathy or carry out other social interactions naturally with the victim**<sup>perceived negative anthropomorphism</sup>",
            "lack of autonomy",
            "no spontaneous action",
            "unexpectedly destroyed: One could be afraid and destroy the robot",
            "lack of empathy: **Robots have 0 empathy and sympathy for the injured**<sup>lack of empathy</sup>.",
            "compassion: The robot is not a living being and therefore cannot provide emotional support to potential victims.",
            "flexibility / intuition",
            "***\n\n**lack of human closeness**<sup>perceived negative anthropomorphism</sup>: Let's say if victims of earthquakes are mostly only cared for by rescue robots, this could come across as cold to the affected people - perhaps also as if they weren't worth direct human help or the risk."
        ],
        "code_descriptions": {
            "empathy": "Identifies instances where participants express a lack of ability or difficulty in empathizing with the emotions or experiences of others, particularly in relation to autonomous actions of rescue robots. \n\n*** \n\nParticipants highlighted their struggle to empathize with the victims' emotions as the robots operated autonomously during rescue missions.",
            "perspective": "Captures instances where participants discuss the absence of human involvement in interactions with artificial intelligence, highlighting a shift in perspective towards non-human entities. \n\n*** \n\nParticipants emphasized the reliance on AI systems and the lack of human intervention in decision-making processes.",
            "perceived negative anthropomorphism": "Identifies instances where participants express discomfort or unease towards rescue robots due to their human-like characteristics, such as an intimidating appearance.",
            "lack of alignment": "Identifies instances where the concept of autonomy is viewed as conflicting with the objectives of rescue missions. \n\n*** \n\nChallenges arise due to the lack of alignment between the need for independent decision-making and the structured nature of rescue operations. \n\n*** \n\nParticipants express concerns about the lack of alignment between the capabilities of rescue robots and the specific requirements of complex search and rescue scenarios.",
            "lack of empathy": "Identifies instances where participants express concerns about the absence of emotional understanding or compassion in rescue robots, highlighting the perceived limitations in empathetic capabilities. \n\n*** \n\nParticipants noted that the lack of empathy in rescue robots could hinder their ability to provide effective emotional support during emergencies. \n\n*** \n\nThe absence of sympathy in robotic interactions was seen as a significant drawback, potentially impacting the quality of care and human-robot relationships in rescue scenarios."
        }
    }
]