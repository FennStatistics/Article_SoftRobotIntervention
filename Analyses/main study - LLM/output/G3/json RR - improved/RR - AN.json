[
    {
        "robot": "RR",
        "category": "AN",
        "coded_texts": [
            "limited autonomy",
            "No feelings: **Can't empathize with the victims' feelings when the robots work autonomically**<sup>empathy</sup>",
            "decision-making ability",
            "lack of humanity: **AI and no human**<sup>perspective</sup>. what does it look like from the perspective of people who are being saved",
            "lack of empathy",
            "no emotion",
            "**intimidating appearance**<sup>perceived negative anthropomorphism</sup>: a robot could seem frightening",
            "autonomy: **Autonomy as a contradiction to rescue goals**<sup>lack of alignment</sup>",
            "lack of empathy: Victims could be treated improperly",
            "no human thinking",
            "no empathy",
            "limited cognition",
            "have no feelings",
            "lack of emotional support: Sometimes people need to endure in their predicament, should they be trapped. Here, a human rescuer can provide emotional support.",
            "***imitation of nature: Human-like characteristics might not be well received by every person and could cause discomfort.***<sup>perceived negative anthropomorphism</sup>",
            "lack of responsibility: **with autonomous robots**<sup>lack of alignment</sup>",
            "lack of human judgment",
            "***errors in autonomy***<sup>perceived negative anthropomorphism</sup>: Autonomously working robots can make mistakes because they judge complex relationships worse.",
            "**inhuman: A victim that can be saved is probably not used to dealing with such machines and would not know how to behave. It cannot show empathy or carry out other social interactions naturally with the victim**<sup>perceived negative anthropomorphism</sup>",
            "lack of autonomy",
            "no spontaneous action",
            "unexpectedly destroyed: One could be afraid and destroy the robot",
            "lack of empathy: **Robots have 0 empathy and sympathy for the injured**<sup>lack of empathy</sup>.",
            "compassion: The robot is not a living being and therefore cannot provide emotional support to potential victims.",
            "flexibility / intuition",
            "***\n\n**lack of human closeness**<sup>perceived negative anthropomorphism</sup>: Let's say if victims of earthquakes are mostly only cared for by rescue robots, this could come across as cold to the affected people - perhaps also as if they weren't worth direct human help or the risk."
        ],
        "code_descriptions": {
            "lack of empathy": "Identifies instances where participants express concerns about the absence of emotional understanding or compassion in rescue robots, including the lack of human closeness. Participants noted that the absence of empathy could hinder the robots' effectiveness in providing emotional support, impacting the quality of care and human-robot relationships in rescue scenarios.",
            "perspective": "Captures instances where participants discuss the absence of human involvement in interactions with artificial intelligence, emphasizing the reliance on AI systems and the lack of human intervention in decision-making processes.",
            "perceived negative anthropomorphism": "Identifies instances where participants express discomfort or unease towards rescue robots due to their human-like characteristics, including their imitation of nature, intimidating appearance, and how these traits might evoke feelings of unease.",
            "lack of alignment": "Identifies instances where the concept of autonomy is viewed as conflicting with the objectives of rescue missions, highlighting challenges between independent decision-making and the structured requirements of rescue operations. Participants expressed concerns about the lack of alignment between the robots' capabilities and the specific needs of complex scenarios.",
            "errors in autonomy": "Highlights errors or shortcomings arising from the autonomous functioning of robots, including their potential to make incorrect or suboptimal decisions in rescue scenarios.",
            "lack of human judgment": "Identifies concerns regarding the absence of human reasoning and intuition in rescue robots, emphasizing the limitations of robotic decision-making compared to human judgment."
        }
    }
]