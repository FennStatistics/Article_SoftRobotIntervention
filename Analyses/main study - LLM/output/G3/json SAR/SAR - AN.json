[
    {
        "robot": "SAR",
        "category": "AN",
        "coded_texts": [
            "feigning empathy: **The described robots do not react as a living being would**<sup>empathy</sup>. They have no will and no feelings. **The reactions are deceptive as they suggest empathy to those in need**<sup>deception</sup>.",
            "limited emotional intelligence",
            "No human empathy",
            "***\n\n**without empathy**<sup>empathy</sup>: Cannot respond to emotions despite objectivity or possibly not like a human would.",
            "life-like properties",
            "not creative: no imagination",
            "no real person",
            "Lack of emotions",
            "Lack of empathy",
            "**Not empathetic (enough): Robots cannot empathize or understand human emotions.**<sup>empathy</sup>",
            "lack of empathy",
            "no emotions",
            "No human warmth",
            "Replacement impossible: **real human interaction is complex and nuanced, a mechanical replacement is hardly possible**<sup>complexity; limitations</sup>",
            "not human-like",
            "emotional integrity: **The robot cannot offer human emotions to people**<sup>limitations</sup>",
            "expectation of AI",
            "not spontaneous: **Assistance robots cannot react spontaneously to new experiences**<sup>lack of adaptability</sup>.",
            "***no empathy: The robots cannot feel or express empathy, only artificial empathy, which is often seen through***<sup>deception</sup>",
            "only fake empathy",
            "lack of empathy?",
            "societal awkwardness",
            "no empathy",
            "uncanny valley",
            "reading emotions: can misinterpret emotions",
            "***Lack of intuition: all skills are programmed and therefore based on a database. Human intuition etc. are not possible***<sup>intuition</sup>",
            "no human closeness",
            "***humanization of robots: Robots can become reference persons through use with children or elderly people, which could potentially be harmful to the person***<sup>harmful potential</sup>. **Hacking and then coaxing the person to do something**<sup>manipulation</sup>. **Emotional bonds are broken when the robot is broken**<sup>emotional impact</sup>.",
            "seriousness: Is Robi taken seriously as an assistant?",
            "\"uncanny valley\": **Anthropomorphized robots are often perceived as creepy**<sup>perception</sup>",
            "human warmth: **and gentle touch (comfort) cannot really be conveyed by the robot**<sup>limitations</sup>",
            "negative perceptions: opposite robots",
            "therapy robots: **People should help people and not be replaced by robots**<sup>ethics</sup>",
            "disappearing boundaries: **The line between human and machine is disappearing**<sup>technological advancement</sup>",
            "uncanny valley: **Robots could suddenly seem alien and scary in interaction, when one becomes aware of their artificiality again**<sup>uncanny valley</sup>",
            "no spontaneous action",
            "emotionally cold",
            "no \"real\" empathy",
            "limitation: **Robots can only partially replace human communication**<sup>limitations</sup>"
        ],
        "code_descriptions": {
            "empathy": "Identifies instances where participants express a lack of emotional responsiveness or understanding in socially assistive robots, highlighting a perceived absence of empathy in their interactions. \n\n*** \n\nParticipants noted that the robots' responses felt scripted and devoid of genuine emotional connection, emphasizing a desire for more empathetic interactions in their interactions with socially assistive robots.",
            "deception": "Identifies instances in the data where participants describe deceptive behaviors or actions that imply empathy towards individuals requiring assistance.",
            "complexity": "Captures references to the intricate and multifaceted nature of human interaction, suggesting skepticism towards the feasibility of mechanical substitutes.",
            "limitations": "Highlights the acknowledgment of the intricate nature of human interaction and the skepticism towards the feasibility of substituting it with mechanical alternatives. \n\n*** \n\nthe technology has its limitations, especially in understanding and responding to human emotions and needs***while robots can assist in certain tasks, their limitations in emotional intelligence and understanding human nuances are evident***the participants expressed concerns about the limitations of robots in providing genuine emotional support and connection",
            "lack of adaptability": "Identifies instances where socially assistive robots are described as lacking the ability to adapt to new situations or experiences, potentially limiting their effectiveness in providing support and assistance.",
            "intuition": "Captures instances where participants express skepticism towards socially assistive robots' ability to exhibit human-like intuition, emphasizing reliance on programmed skills over intuitive understanding.",
            "harmful potential": "Identifies instances where the anthropomorphism of socially assistive robots is perceived as having the potential to cause harm, particularly in scenarios involving vulnerable populations like children or the elderly.",
            "manipulation": "Identifies instances in the data where individuals describe actions involving unauthorized access or coercion to influence behavior. \n\n*** \n\nThe individual was manipulated into revealing sensitive information. *** The study participants discussed instances where technology was used for manipulation rather than assistance.",
            "emotional impact": "Captures instances where participants express the disruption or strain on emotional connections when the socially assistive robot malfunctions or ceases to function.",
            "perception": "Captures the varied ways in which individuals interpret and feel about anthropomorphized robots, ranging from positive to negative perceptions. \n\n*** \n\nParticipants expressed a sense of comfort and companionship when interacting with anthropomorphized robots, highlighting the positive impact on their emotional well-being.\n\n*** \n\nSome participants mentioned feeling uneasy and unsettled by the human-like features of socially assistive robots, indicating a negative perception of anthropomorphism in this context.",
            "ethics": "Captures concerns about the ethical implications of replacing human interactions with robots in the context of social assistance. \n\n*** \n\nRobots should not be given the power to make decisions that affect human lives, as this raises ethical concerns. \n\n*** \n\nThe use of socially assistive robots should be carefully monitored to ensure that ethical standards are upheld and human values are respected.",
            "technological advancement": "Identifies instances where participants express observations or concerns about the blurring boundary between humans and machines in the context of socially assistive robots, reflecting on the impact of technological advancement.",
            "uncanny valley": "Identifies instances where participants express discomfort or fear when socially assistive robots exhibit characteristics that remind them of their artificial nature, leading to a sense of unease or alienation. \n\n***Robots could suddenly seem alien and scary in interaction, when one becomes aware of their artificiality again***"
        }
    }
]